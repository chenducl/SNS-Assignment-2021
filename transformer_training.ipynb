{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ef9226f5f281bed155f6877abe961f8893e93036b236b1a7e5395de73a55139a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Model Training\n",
    "\n",
    "- [TODO] Transformer Timeseries Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessities\n",
    "import os\n",
    "import datetime\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readning in the dataset\n",
    "dataset_csv = pd.read_csv('./data/dataset.csv', index_col=0)\n",
    "dataset_rolling_csv = pd.read_csv('./data/dataset_rolling.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, dataset, feature_cols, label_cols, timestamp=14, \n",
    "                        batch_size=1, test_size=0.03):\n",
    "        ''' Initialize the dataset\n",
    "        :param dataset: Dataframe of the dataset\n",
    "        :param feature_cols: list of feature names,\n",
    "            e.g. ['dates', 'vaccinations'] means using dates and vaccinations as features\n",
    "        :param label_cols: list of prediction targets,\n",
    "            e.g. ['confirmed'] means using confirmed data as labels\n",
    "        :param timestamp: timestamp in LSTM model\n",
    "        :param test_size: the ratio of test data in the dataset\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.feature_cols = feature_cols\n",
    "        self.label_cols = label_cols\n",
    "        self.timestamp = timestamp\n",
    "        self.batch_size = batch_size\n",
    "        self.test_size = test_size\n",
    "        # Split features and labels\n",
    "        self.features = self.dataset[feature_cols]\n",
    "        self.labels = self.dataset[label_cols]\n",
    "        # Normalize the dataset using MinMaxScaler before training\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.dataset.loc[:, dataset.columns != 'dates'] = self.scaler.fit_transform(dataset.loc[:, dataset.columns != 'dates'])\n",
    "        # Split the dataset\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "                self.features, self.labels, test_size=self.test_size, shuffle=False)\n",
    "    \n",
    "    def get_training_set(self):\n",
    "        ''' Return the time-series generator used for training\n",
    "        '''\n",
    "        return TimeseriesGenerator(self.x_train.to_numpy(), self.y_train.to_numpy(),\n",
    "                length=self.timestamp, batch_size=self.batch_size)\n",
    "    \n",
    "    def get_test_set(self):\n",
    "        ''' Return the time-series generator used for testing\n",
    "        '''\n",
    "        return TimeseriesGenerator(self.x_test.to_numpy(), self.y_test.to_numpy(),\n",
    "                length=self.timestamp, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "    ''' Other models are derived by inheritance from BaseModel.\n",
    "    '''\n",
    "    def __init__(self, dataset, model_path, output_dim, epochs,\n",
    "                        verbose, loss, optimizer, dropout, **args):\n",
    "        ''' Initialize the model parameters\n",
    "        param dataset: dataset Dataframe\n",
    "        param output_dim: output dimension\n",
    "        param epochs: training epochs\n",
    "        param verbose: verbose level of logging\n",
    "        param loss: loss function for training\n",
    "        param optimizer: optimizer for training\n",
    "        '''\n",
    "        self.dataset = dataset\n",
    "        self.model_path = model_path\n",
    "        self.output_dim = output_dim\n",
    "        self.epochs = epochs\n",
    "        self.verbose = verbose\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def read_model(self):\n",
    "        ''' Load model from the given path\n",
    "        '''\n",
    "        self.model = load_model(self.model_path)\n",
    "\n",
    "    def train(self):\n",
    "        ''' Training\n",
    "        '''\n",
    "        training_set = self.dataset.get_training_set()\n",
    "        self.model.fit(training_set, epochs=self.epochs, verbose=self.verbose)\n",
    "    \n",
    "    def save_model(self):\n",
    "        ''' Save model to path\n",
    "        '''\n",
    "        self.model.save(self.model_path)\n",
    "    \n",
    "    def predict(self, input):\n",
    "        return self.model.predict(input)\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.title('Labels and Predictions on ' + ', '.join(self.dataset.label_cols))\n",
    "        plt.plot(self.dataset.y_train, label='Labels')\n",
    "        plt.plot(self.model.predict(self.dataset.get_training_set()), label='Predictions')\n",
    "        plt.legend()\n",
    "        "
   ]
  }
 ]
}